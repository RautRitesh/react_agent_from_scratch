{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "import re\n",
        "import httpx"
      ],
      "metadata": {
        "id": "VAtNsQ2IqZf3"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key=\"...\""
      ],
      "metadata": {
        "id": "E0T6Gt8ArhBY"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Chatbot():\n",
        "  def __init__(self,system=\"\"):\n",
        "    self.system=system\n",
        "    self.message=[]\n",
        "    if self.system:\n",
        "      self.message.append({\"role\":\"system\",\"content\":system})\n",
        "\n",
        "  def __call__(self,message):\n",
        "    self.message.append({\"role\":\"user\",\"content\":message})\n",
        "    result=self.execute()\n",
        "    self.message.append({\"role\":\"assistant\",\"content\":result})\n",
        "    return result\n",
        "\n",
        "\n",
        "  def execute(self):\n",
        "    llm=ChatGroq(model=\"openai/gpt-oss-20b\",api_key=api_key)\n",
        "    result=llm.invoke(self.message)\n",
        "    return result.content"
      ],
      "metadata": {
        "id": "L0TS2JmYqf5I"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "action_re=re.compile(r'^Action: (\\w+): (.*)')\n",
        "def wikipedia(query):\n",
        "  response=httpx.get(\"https://en.wikipedia.org/w/api.php\",\n",
        "                     params={\n",
        "                         \"action\":\"query\",\n",
        "                         \"list\":\"search\",\n",
        "                         \"srsearch\":query,\n",
        "                         \"format\":\"json\"\n",
        "                     })\n",
        "  print(response)\n",
        "  return response.json()[\"query\"][\"search\"][0][\"snippet\"]\n",
        "\n",
        "def calculate(number):\n",
        "  return eval(number)"
      ],
      "metadata": {
        "id": "0v49hL2DsBHi"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "known_actions={\n",
        "    \"wikipedia\":wikipedia,\n",
        "    \"calculate\":calculate\n",
        "}"
      ],
      "metadata": {
        "id": "9BWx0rKjuF7W"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "You run in a loop of Thought, Action, PAUSE, Observation.\n",
        "At the end of the loop you output an Answer.\n",
        "\n",
        "Use Thought to describe your thoughts about the question you have been asked.\n",
        "Use Action to run one of the actions available to you - then return PAUSE.\n",
        "Observation will be the result of running those actions.\n",
        "\n",
        "**IMPORTANT RULES:**\n",
        "1. Output MUST be plain text.\n",
        "2. Do NOT use JSON, XML, or any \"tool_call\" syntax.\n",
        "3. Do NOT try to use native function calling. Just write the text.\n",
        "\n",
        "Your available actions are:\n",
        "calculate:\n",
        "e.g. calculate: 4 * 7 / 3\n",
        "Runs a calculation and returns the number - uses Python so be sure to use floating point\n",
        "syntax if necessary\n",
        "\n",
        "wikipedia:\n",
        "e.g. wikipedia: Django\n",
        "Returns a summary from searching Wikipedia\n",
        "\n",
        "Example session:\n",
        "Question: What is the capital of France?\n",
        "Thought: I should look up France on Wikipedia\n",
        "Action: wikipedia: France\n",
        "PAUSE\n",
        "\n",
        "You will be called again with this:\n",
        "Observation: France is a country. The capital is Paris.\n",
        "\n",
        "You then output:\n",
        "Answer: The capital of France is Paris\n",
        "\"\"\".strip()"
      ],
      "metadata": {
        "id": "YDuufssXwExl"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query(question, max_turns=5):\n",
        "  i=0\n",
        "  bot=Chatbot(prompt)\n",
        "  next_prompt=question\n",
        "  while i<max_turns:\n",
        "    i+=1\n",
        "    result=bot(next_prompt)\n",
        "    print(result)\n",
        "    actions=[action_re.match(a) for a in result.split('\\n') if action_re.match(a)]\n",
        "    if actions:\n",
        "      action,action_input=actions[0].groups()\n",
        "      if action not in known_actions:\n",
        "        raise Exception(f\"Unknown action:{action}:{action_input}\")\n",
        "      print(\"--running{}{}\".format(action,action_input))\n",
        "      observation=known_actions[action](action_input)\n",
        "      print(\"obesrvation:\",observation)\n",
        "      next_prompt=f\"Observation:{observation}\"\n",
        "    else:\n",
        "      return result"
      ],
      "metadata": {
        "id": "4cHu6frMsqGP"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(query(\"What is Langchain?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDxizvxevz8H",
        "outputId": "5531e105-ec51-4785-a210-9ce4bba8a0e7"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**LangChain** is an open‑source framework written in Python that helps developers build applications powered by large language models (LLMs).  \n",
            "Key points:\n",
            "\n",
            "| Feature | Description |\n",
            "|---------|-------------|\n",
            "| **LLM Agnosticism** | Works with many providers (OpenAI, Anthropic, Cohere, etc.). |\n",
            "| **Modular Chaining** | Lets you string together prompts, tools, and models into reusable “chains.” |\n",
            "| **Memory & Context** | Provides abstractions for short‑term and long‑term memory, making conversational agents easier to build. |\n",
            "| **Retrieval‑Augmented Generation** | Integrates retrieval systems (e.g., vector stores, databases) so models can access external knowledge. |\n",
            "| **Extensible Tooling** | Supports adding custom tools (APIs, databases, web scraping) that LLMs can call. |\n",
            "| **Community Ecosystem** | Rich set of plugins, examples, and community‑maintained integrations. |\n",
            "\n",
            "In short, LangChain abstracts common patterns in LLM usage—prompt design, chaining, memory, and external data access—so you can focus on building the application logic rather than re‑implementing these building blocks.\n",
            "**LangChain** is an open‑source framework written in Python that helps developers build applications powered by large language models (LLMs).  \n",
            "Key points:\n",
            "\n",
            "| Feature | Description |\n",
            "|---------|-------------|\n",
            "| **LLM Agnosticism** | Works with many providers (OpenAI, Anthropic, Cohere, etc.). |\n",
            "| **Modular Chaining** | Lets you string together prompts, tools, and models into reusable “chains.” |\n",
            "| **Memory & Context** | Provides abstractions for short‑term and long‑term memory, making conversational agents easier to build. |\n",
            "| **Retrieval‑Augmented Generation** | Integrates retrieval systems (e.g., vector stores, databases) so models can access external knowledge. |\n",
            "| **Extensible Tooling** | Supports adding custom tools (APIs, databases, web scraping) that LLMs can call. |\n",
            "| **Community Ecosystem** | Rich set of plugins, examples, and community‑maintained integrations. |\n",
            "\n",
            "In short, LangChain abstracts common patterns in LLM usage—prompt design, chaining, memory, and external data access—so you can focus on building the application logic rather than re‑implementing these building blocks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "skd9wve1wKaw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}